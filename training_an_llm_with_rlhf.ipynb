{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbb4dc51-4878-4b3a-8c3f-16916eb6a1fc",
   "metadata": {
    "id": "dbb4dc51-4878-4b3a-8c3f-16916eb6a1fc"
   },
   "source": [
    "# StatQuest: Training an LLM from Scratch with Pre-Training and Reinforcement Learning with Human Feedback (RLHF)\n",
    "\n",
    "Copyright 2025, Joshua Starmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f69a1c-643c-447f-a4b6-2a62983e4321",
   "metadata": {
    "id": "04f69a1c-643c-447f-a4b6-2a62983e4321"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad3a230-944c-473d-87e4-14639fd2aada",
   "metadata": {
    "id": "cad3a230-944c-473d-87e4-14639fd2aada"
   },
   "source": [
    "In this tutorial we train a very simple **LLM** from scratch with **Pre-Training** and **Reinforcement Learning with Human Feedback** (**RHLF**). This means we'll first **Pre-Train** a simple **LLM**, then we'll use that **LLM** to create **Reward Model**, which will be trained with human preference data. Lastly, we'll use the **Reward Model** to train the original, **Pre-Trained LLM**, to respond appropriately to prompts it has never seen before more with **Reinforcement Learning**.\n",
    "\n",
    "This example is based on the StatQuest video: **[Reinforcement Learning with Human Feedback, Clearly Explained!!!](https://youtu.be/qPN_XZcJf_s)**\n",
    "\n",
    "<img src=\"https://github.com/StatQuest/RLHF/blob/main/images/rlhf_intro.png?raw=1\" alt=\"we will train an llm with pre-training and rlhf\" style=\"width: 800px;\">\n",
    "\n",
    "**NOTE:** The **LLM** that we are going to train is a **Decoder-Only Transformer** and if you would like to learn more about how it works and how to code it, please see these StatQuest videos...\n",
    "- **[Neural Networks Part 15: Decoder-Only Transformers (like ChatGPT)!!!](https://youtu.be/bQ5BoolX9Ag)**\n",
    "- **[The Matrix Math Behind Transformer Neural Networks, One Step at a Time!!!](https://youtu.be/KphmOJnLAdI)**\n",
    "- **[Coding a ChatGPT Like Transformer From Scratch](https://youtu.be/C9QSpl5nmrY)**\n",
    "  \n",
    "...as well as this **[GitHub Repository](https://github.com/StatQuest/decoder_transformer_from_scratch)**.\n",
    "\n",
    "**ALSO NOTE:** We're omitting the **Fine-Tuning** stage from this tutorial because, fundamentally, the techniques used for **Fine-Tuning** are not significantly different from **Pre-Training**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c481e-d47e-45e6-82d0-c43628257b2a",
   "metadata": {
    "id": "a14c481e-d47e-45e6-82d0-c43628257b2a"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac3488-cd89-4aa7-a808-cfc88f59d70d",
   "metadata": {
    "id": "49ac3488-cd89-4aa7-a808-cfc88f59d70d"
   },
   "source": [
    "# Import the modules that will do all the work\n",
    "\n",
    "The very first thing we need to do is load a bunch of Python modules. Python itself is just a basic programming language. These modules give us extra functionality to create and train the neural networks we'll use.\n",
    "\n",
    "**NOTE:** The code below will check and see if **Lightning** is installed, and if not, it will install it for you. However, if you also need to install PyTorch, check out there install page **[here.](https://pytorch.org/get-started/locally/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd72aa-76ec-43b2-8e72-8278f41ff5bc",
   "metadata": {
    "id": "bcbd72aa-76ec-43b2-8e72-8278f41ff5bc"
   },
   "outputs": [],
   "source": [
    "## First, check to see if lightning is installed, if not, install it.\n",
    "import pip\n",
    "try:\n",
    "  __import__(\"lightning\")\n",
    "except ImportError:\n",
    "  pip.main(['install', \"lightning\"])\n",
    "\n",
    "import torch ## torch let's us create tensors and also provides helper functions\n",
    "import torch.nn as nn ## torch.nn gives us nn.Module(), nn.Embedding() and nn.Linear()\n",
    "import torch.nn.functional as F # This gives us the softmax() and argmax()\n",
    "from torch.optim import Adam ## We will use the Adam optimizer, which is, essentially,\n",
    "                             ## a slightly less stochastic version of stochastic gradient descent.\n",
    "from torch.utils.data import TensorDataset, DataLoader ## We'll store our data in DataLoaders\n",
    "\n",
    "import lightning as L ## Lightning makes it easier to write, optimize and scale our code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y_bouk4QlS0h",
   "metadata": {
    "id": "Y_bouk4QlS0h"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jgd2bfxElUWM",
   "metadata": {
    "id": "jgd2bfxElUWM"
   },
   "source": [
    "# Define the model dimension and number of tokens we can process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b762a0-5da0-435c-b5bb-ac9d515c9991",
   "metadata": {
    "id": "21b762a0-5da0-435c-b5bb-ac9d515c9991"
   },
   "outputs": [],
   "source": [
    "## In this example we're increasing the model dimension to 4, meaning\n",
    "## each token will have 4 values associated with it.\n",
    "model_dimension = 4\n",
    "if (model_dimension % 2 != 0):\n",
    "    print(\"NOTE: Due to how position encoding is coded, model_dimension must be an even number.\")\n",
    "\n",
    "## We're also increasing the number of tokens our model can handle\n",
    "max_length = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UElLx3Gole32",
   "metadata": {
    "id": "UElLx3Gole32"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PtMf4fPPlf8i",
   "metadata": {
    "id": "PtMf4fPPlf8i"
   },
   "source": [
    "# Build vocabulary and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f890c6-9f5c-4148-8407-5e3d11363fb1",
   "metadata": {
    "id": "00f890c6-9f5c-4148-8407-5e3d11363fb1"
   },
   "outputs": [],
   "source": [
    "## In this example, we're simplifying\n",
    "## how to add tokens to our vocabulary\n",
    "tokens = ['what',\n",
    "          'is',\n",
    "          'statquest',\n",
    "          'awesome',\n",
    "          'squatch',\n",
    "          'eats',\n",
    "          'pizza',\n",
    "          'norm',\n",
    "          '<EOS>',\n",
    "          '<PAD>']\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fcbf1a-963b-45f5-bcdf-464af2a99057",
   "metadata": {
    "id": "f2fcbf1a-963b-45f5-bcdf-464af2a99057"
   },
   "outputs": [],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239d01c9-f5da-4af1-bbd2-b0fbbeebf86a",
   "metadata": {
    "id": "239d01c9-f5da-4af1-bbd2-b0fbbeebf86a"
   },
   "outputs": [],
   "source": [
    "ids = list(range(len(tokens)))\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5b70e9-d7b5-4182-a94f-95a97a680999",
   "metadata": {
    "id": "ab5b70e9-d7b5-4182-a94f-95a97a680999"
   },
   "outputs": [],
   "source": [
    "token_to_id = dict(zip(tokens, ids))\n",
    "id_to_token = dict(map(reversed, token_to_id.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77001e1-d0e8-4fa8-97d6-8086d7aefba6",
   "metadata": {
    "id": "f77001e1-d0e8-4fa8-97d6-8086d7aefba6"
   },
   "outputs": [],
   "source": [
    "## In this example, we're simplifying how to convert tokens to ids and ids to tokens.\n",
    "## I got this idea from looking at some of andrej karpathy's code\n",
    "def tokens2ids(tokens):\n",
    "    output = []\n",
    "    for token in tokens.split():\n",
    "        output.append(token_to_id[token])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37c5aa4-7afc-4d1f-b420-ee846a1e72f1",
   "metadata": {
    "id": "f37c5aa4-7afc-4d1f-b420-ee846a1e72f1"
   },
   "outputs": [],
   "source": [
    "def ids2tokens(ids):\n",
    "    output = []\n",
    "    for id in ids:\n",
    "        output.append(id_to_token[id])\n",
    "\n",
    "    return \" \".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa819d15-5f1d-4410-9276-3ca5a0a31338",
   "metadata": {
    "id": "aa819d15-5f1d-4410-9276-3ca5a0a31338"
   },
   "outputs": [],
   "source": [
    "## Now let's test the functions out by converting\n",
    "## a prompt into ids...\n",
    "tokens2ids(\"what is statquest <EOS>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0af242-0062-4e10-b493-97af0a85db50",
   "metadata": {
    "id": "ff0af242-0062-4e10-b493-97af0a85db50"
   },
   "outputs": [],
   "source": [
    "## ...and then converting those ids back into tokens\n",
    "ids2tokens(tokens2ids(\"what is statquest <EOS>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JPkIYgtfm42I",
   "metadata": {
    "id": "JPkIYgtfm42I"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9z2baSZEm6WM",
   "metadata": {
    "id": "9z2baSZEm6WM"
   },
   "source": [
    "# Create Traing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b7b06-1311-4fd3-b57d-792713c1032e",
   "metadata": {
    "id": "e41b7b06-1311-4fd3-b57d-792713c1032e"
   },
   "outputs": [],
   "source": [
    "## We've also got a somewhat larger pre-training dataset then we had before\n",
    "\n",
    "pretrain_inputs = torch.tensor([tokens2ids(\"what is statquest <EOS> awesome\"),\n",
    "                                tokens2ids(\"statquest is what <EOS> awesome\"),\n",
    "                                tokens2ids(\"what is norm <EOS> awesome\"),\n",
    "                                tokens2ids(\"what is squatch <EOS> awesome\"),\n",
    "                                tokens2ids(\"norm is what <EOS> awesome\"),\n",
    "                                tokens2ids(\"squatch is what <EOS> awesome\"),\n",
    "                                tokens2ids(\"squatch eats what <EOS> pizza\")])\n",
    "pretrain_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0920e2e7-8b02-405d-848b-6d04c81d3903",
   "metadata": {
    "id": "0920e2e7-8b02-405d-848b-6d04c81d3903"
   },
   "outputs": [],
   "source": [
    "## We can verify that the inputs were created correctly\n",
    "## by converting the first row of pretrain_input ids back into tokens.\n",
    "ids2tokens(pretrain_inputs[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bcb4ab-f629-47a8-a89f-ba00f7af2940",
   "metadata": {
    "id": "e5bcb4ab-f629-47a8-a89f-ba00f7af2940"
   },
   "outputs": [],
   "source": [
    "pretrain_labels = torch.tensor([tokens2ids(\"is statquest <EOS> awesome <EOS>\"),\n",
    "                                tokens2ids(\"is what <EOS> awesome <EOS>\"),\n",
    "                                tokens2ids(\"is norm <EOS> awesome <EOS>\"),\n",
    "                                tokens2ids(\"is squatch <EOS> awesome <EOS>\"),\n",
    "                                tokens2ids(\"is what <EOS> awesome <EOS>\"),\n",
    "                                tokens2ids(\"is what <EOS> awesome <EOS>\"),\n",
    "                                tokens2ids(\"eats what <EOS> pizza <EOS>\")])\n",
    "pretrain_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc8a30-639d-44b7-a198-3ad84039b68e",
   "metadata": {
    "id": "a0fc8a30-639d-44b7-a198-3ad84039b68e"
   },
   "outputs": [],
   "source": [
    "## We can verify that the labels were created correctly\n",
    "## by converting the first row of pretrain_labels ids back into tokens.\n",
    "ids2tokens(pretrain_labels[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5a504a-ffd8-42de-a2b9-4320e8c54c08",
   "metadata": {
    "id": "3d5a504a-ffd8-42de-a2b9-4320e8c54c08"
   },
   "outputs": [],
   "source": [
    "## Now let's package everything up into a DataLoader...\n",
    "pretrain_dataset = TensorDataset(pretrain_inputs, pretrain_labels)\n",
    "pretrain_dataloader = DataLoader(pretrain_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546dc65d-c009-43a0-9c2b-9f11051c14ea",
   "metadata": {
    "id": "546dc65d-c009-43a0-9c2b-9f11051c14ea"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28221655-5976-4070-89bc-33814447e6a4",
   "metadata": {
    "id": "28221655-5976-4070-89bc-33814447e6a4"
   },
   "source": [
    "# Code for a basic Decoder-Only Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rlPM-sWrbiRZ",
   "metadata": {
    "id": "rlPM-sWrbiRZ"
   },
   "source": [
    "**NOTE:** For details on how this code works, see these StatQuest videos...\n",
    "- **[Neural Networks Part 15: Decoder-Only Transformers (like ChatGPT)!!!](https://youtu.be/bQ5BoolX9Ag)**\n",
    "- **[The Matrix Math Behind Transformer Neural Networks, One Step at a Time!!!](https://youtu.be/KphmOJnLAdI)**\n",
    "- **[Coding a ChatGPT Like Transformer From Scratch](https://youtu.be/C9QSpl5nmrY)**\n",
    "  \n",
    "...as well as this **[GitHub Repository](https://github.com/StatQuest/decoder_transformer_from_scratch)**.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7330ec8-01ca-46e3-99a3-d3ff45db6158",
   "metadata": {
    "id": "c7330ec8-01ca-46e3-99a3-d3ff45db6158"
   },
   "outputs": [],
   "source": [
    "class PositionEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model=2, max_len=6):\n",
    "        ## d_model = The dimension of the transformer, which is also the number of embedding values per token.\n",
    "        ##           In the transformer I used in the StatQuest: Transformer Neural Networks Clearly Explained!!!\n",
    "        ##           d_model=2, so that's what we'll use as a default for now.\n",
    "        ##           However, in \"Attention Is All You Need\" d_model=512\n",
    "        ## max_len = maximum number of tokens we allow as input.\n",
    "        ##           Since we are precomputing the position encoding values and storing them in a lookup table\n",
    "        ##           we can use d_model and max_len to determine the number of rows and columns in that\n",
    "        ##           lookup table.\n",
    "\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(start=0, end=max_len, step=1).float().unsqueeze(1)\n",
    "\n",
    "        embedding_index = torch.arange(start=0, end=d_model, step=2).float()\n",
    "        div_term = 1/torch.tensor(10000.0)**(embedding_index / d_model)\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) ## every other column, starting with the 1st, has sin() values\n",
    "        pe[:, 1::2] = torch.cos(position * div_term) ## every other column, starting with the 2nd, has cos() values\n",
    "        ## Now we \"register 'pe'.\n",
    "        self.register_buffer('pe', pe) ## \"register_buffer()\" ensures that\n",
    "                                       ## 'pe' will be moved to wherever the model gets\n",
    "                                       ## moved to. So if the model is moved to a GPU, then,\n",
    "                                       ## even though we don't need to optimize 'pe', it will\n",
    "                                       ## also be moved to that GPU. This, in turn, means\n",
    "                                       ## that accessing 'pe' will be relatively fast compared\n",
    "                                       ## to having a GPU have to get the data from a CPU.\n",
    "\n",
    "    def forward(self, word_embeddings):\n",
    "\n",
    "        return word_embeddings + self.pe[:word_embeddings.size(0), :] ## word_embeddings.size(0) = number of embeddings\n",
    "                                                                      ## NOTE: That second ':' is optional and\n",
    "                                                                      ## we could re-write it like this:\n",
    "                                                                      ## self.pe[:word_embeddings.size(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f296c-07e9-4186-9ca5-46f0518a5134",
   "metadata": {
    "id": "c65f296c-07e9-4186-9ca5-46f0518a5134"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model=2):\n",
    "        ## d_model = the number of embedding values per token.\n",
    "        ##           In the transformer I used in the StatQuest: Transformer Neural Networks Clearly Explained!!!\n",
    "        ##           d_model=2, so that's what we'll use as a default for now.\n",
    "        ##           However, in \"Attention Is All You Need\" d_model=512\n",
    "\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model=d_model\n",
    "\n",
    "        self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "        self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "        self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "\n",
    "        self.row_dim = 0\n",
    "        self.col_dim = 1\n",
    "\n",
    "\n",
    "    def forward(self, encodings_for_q, encodings_for_k, encodings_for_v, mask=None):\n",
    "\n",
    "        q = self.W_q(encodings_for_q)\n",
    "        k = self.W_k(encodings_for_k)\n",
    "        v = self.W_v(encodings_for_v)\n",
    "\n",
    "        ## Compute attention scores\n",
    "        ## the equation is (q * k^T)/sqrt(d_model)\n",
    "        sims = torch.matmul(q, k.transpose(dim0=self.row_dim, dim1=self.col_dim))\n",
    "\n",
    "        scaled_sims = sims / torch.tensor(k.size(self.col_dim)**0.5)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9) # I've also seen -1e20 and -9e15 used in masking\n",
    "\n",
    "        attention_percents = F.softmax(scaled_sims, dim=self.col_dim)\n",
    "\n",
    "        attention_scores = torch.matmul(attention_percents, v)\n",
    "\n",
    "        return attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bccaaa4-7498-482f-aa06-53d914b12aa7",
   "metadata": {
    "id": "6bccaaa4-7498-482f-aa06-53d914b12aa7"
   },
   "outputs": [],
   "source": [
    "class DecoderOnlyTransformer(L.LightningModule):\n",
    "\n",
    "    def __init__(self, num_tokens=4, d_model=2, max_len=6):\n",
    "\n",
    "        super().__init__()\n",
    "        L.seed_everything(seed=42, workers=True)\n",
    "\n",
    "        self.we = nn.Embedding(num_embeddings=num_tokens,\n",
    "                               embedding_dim=d_model)\n",
    "\n",
    "        self.pe = PositionEncoding(d_model=d_model,\n",
    "                                   max_len=max_len)\n",
    "\n",
    "        self.self_attention = Attention(d_model=d_model)\n",
    "\n",
    "        self.fc_layer = nn.Linear(in_features=d_model,\n",
    "                                  out_features=num_tokens)\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    def forward(self, token_ids):\n",
    "\n",
    "        word_embeddings = self.we(token_ids)\n",
    "\n",
    "        position_encoded = self.pe(word_embeddings)\n",
    "\n",
    "        mask = torch.tril(torch.ones((token_ids.size(dim=0), token_ids.size(dim=0)), device=self.device))\n",
    "        mask = mask == 0\n",
    "\n",
    "        self_attention_values = self.self_attention(position_encoded,\n",
    "                                                    position_encoded,\n",
    "                                                    position_encoded,\n",
    "                                                    mask=mask)\n",
    "\n",
    "        residual_connection_values = position_encoded + self_attention_values\n",
    "\n",
    "        fc_layer_output = self.fc_layer(residual_connection_values)\n",
    "\n",
    "        return fc_layer_output\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_tokens, labels = batch # collect input\n",
    "        output = self.forward(input_tokens[0])\n",
    "        loss = self.loss(output, labels[0])\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c369dc02-1973-4299-bf31-0653fa31ebd4",
   "metadata": {
    "id": "c369dc02-1973-4299-bf31-0653fa31ebd4"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4358cdb2-9375-4b26-b2c5-f7799e197c56",
   "metadata": {
    "id": "4358cdb2-9375-4b26-b2c5-f7799e197c56"
   },
   "source": [
    "# Create and test a basic Decoder-Only Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a0ec2-95fd-4fa4-b3af-a243e0194f0b",
   "metadata": {
    "id": "f90a0ec2-95fd-4fa4-b3af-a243e0194f0b"
   },
   "outputs": [],
   "source": [
    "## First, create a model from DecoderOnlyTransformer()\n",
    "model = DecoderOnlyTransformer(num_tokens=len(tokens),\n",
    "                               d_model=model_dimension,\n",
    "                               max_len=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735d9ef8-e8e6-4f53-a714-6b1abfa5c82f",
   "metadata": {
    "id": "735d9ef8-e8e6-4f53-a714-6b1abfa5c82f"
   },
   "outputs": [],
   "source": [
    "## Because tutorial involves creating a bunch of models\n",
    "## and seeing what kind of output they generate in response\n",
    "## to different prompts, we're writing a function to handle\n",
    "## generating output from any model.\n",
    "\n",
    "def generate_output(model, prompt):\n",
    "    input_length = prompt.size(dim=0)\n",
    "\n",
    "    predictions = model(prompt)\n",
    "    predicted_id = torch.tensor([torch.argmax(predictions[-1,:])])\n",
    "    predicted_ids = predicted_id\n",
    "\n",
    "    for i in range(input_length, max_length):\n",
    "        if (predicted_id == token_to_id[\"<EOS>\"]): # if the prediction is <EOS>, then we are done\n",
    "            break\n",
    "\n",
    "        prompt = torch.cat((prompt, predicted_id))\n",
    "\n",
    "        predictions = model(prompt)\n",
    "        predicted_id = torch.tensor([torch.argmax(predictions[-1,:])])\n",
    "        predicted_ids = torch.cat((predicted_ids, predicted_id))\n",
    "\n",
    "    print(\"Predicted Tokens:\\n\")\n",
    "    print(\"\\t\", ids2tokens(predicted_ids.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Fv7ksL02oaCt",
   "metadata": {
    "id": "Fv7ksL02oaCt"
   },
   "source": [
    "Now that we have a nice helper function for generating output from our model, let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed790a1-e71a-4085-bcc4-58c77b45cc7e",
   "metadata": {
    "id": "5ed790a1-e71a-4085-bcc4-58c77b45cc7e"
   },
   "outputs": [],
   "source": [
    "## Now test out the transformer...\n",
    "generate_output(model, torch.tensor(tokens2ids(\"what is statquest <EOS>\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cUhNCv1BnPbG",
   "metadata": {
    "id": "cUhNCv1BnPbG"
   },
   "source": [
    "Since the output from the output from the model isn't ideal, let's train it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f2f6c7-bcc4-46c7-8bfc-43b1e3c8cd18",
   "metadata": {
    "id": "c1f2f6c7-bcc4-46c7-8bfc-43b1e3c8cd18"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049b95ff-893e-4219-b655-8451c069b3b1",
   "metadata": {
    "id": "049b95ff-893e-4219-b655-8451c069b3b1"
   },
   "source": [
    "# Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44814960-8b6c-4477-be2a-c6b12e61a9a7",
   "metadata": {
    "id": "44814960-8b6c-4477-be2a-c6b12e61a9a7"
   },
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs=30, deterministic=True)\n",
    "trainer.fit(model, train_dataloaders=pretrain_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f600f2-5bc2-443e-b8cd-13814a6d9dbe",
   "metadata": {
    "id": "43f600f2-5bc2-443e-b8cd-13814a6d9dbe"
   },
   "outputs": [],
   "source": [
    "## Now test out the transformer and see if training was successful...\n",
    "generate_output(model, torch.tensor(tokens2ids(\"what is statquest <EOS>\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vNmWHQagoi8M",
   "metadata": {
    "id": "vNmWHQagoi8M"
   },
   "source": [
    "Hooray! Our model is generating the correct output for the first prompt. Now let's try a different prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc645dc-fed3-4d58-965b-7e37988ed3dc",
   "metadata": {
    "id": "4cc645dc-fed3-4d58-965b-7e37988ed3dc"
   },
   "outputs": [],
   "source": [
    "generate_output(model, torch.tensor(tokens2ids(\"statquest is what <EOS>\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Rkm6ROMiozjM",
   "metadata": {
    "id": "Rkm6ROMiozjM"
   },
   "source": [
    "Double Hooray!! That worked too! Now that we have successully trained, or **pre-trained**, or model, we can use it to create a **Reward Model**. The **Reward Model** will, ultimately, be trained, with **Human Feedback**, to score outputs generated by our model. These scores will then be used to train our moodel with **Reinforcement Learning** to respond appropriately to prompts it was never trained on.\n",
    "\n",
    "**NOTE:** Typically you **Fine-tune** a model before using it to create a **Reward Model**. However, we're skipping that step because the techniques are essentially the same as **Pre-Training**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da58958-10ec-4b79-ae1e-12850952a34b",
   "metadata": {
    "id": "1da58958-10ec-4b79-ae1e-12850952a34b"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06594fdf-3848-4eec-bdca-2e19386a2ee6",
   "metadata": {
    "id": "06594fdf-3848-4eec-bdca-2e19386a2ee6"
   },
   "source": [
    "# Create and train a Reward Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03802f05-8a2d-4c5a-8fcf-cd5f3b53ae38",
   "metadata": {
    "id": "03802f05-8a2d-4c5a-8fcf-cd5f3b53ae38"
   },
   "source": [
    "The **Reward Model** is a copy of the original model, but with the last layer, the **Fully Connected Layer** that conects the attention layer to the output layer vocabulary, replaced with a much simplier **Fully Connected Layer** that just has a single output. This **Fully Connected Layer** is called a **Regression Layer**, since outputs a single continuous value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54745a5-03cb-4fb2-b55d-68cca98c6cb8",
   "metadata": {
    "id": "e54745a5-03cb-4fb2-b55d-68cca98c6cb8"
   },
   "outputs": [],
   "source": [
    "class RewardModel(L.LightningModule):\n",
    "\n",
    "    def __init__(self, num_tokens=4, d_model=2, max_len=6):\n",
    "\n",
    "        super().__init__()\n",
    "        L.seed_everything(seed=42, workers=True)\n",
    "\n",
    "        self.we = nn.Embedding(num_embeddings=num_tokens,\n",
    "                               embedding_dim=d_model)\n",
    "\n",
    "        self.pe = PositionEncoding(d_model=d_model,\n",
    "                                   max_len=max_len)\n",
    "\n",
    "        self.self_attention = Attention(d_model=d_model)\n",
    "\n",
    "        self.regression_layer = nn.Linear(in_features=d_model,\n",
    "                                          out_features=1)\n",
    "\n",
    "\n",
    "    def forward(self, token_ids):\n",
    "\n",
    "        word_embeddings = self.we(token_ids)\n",
    "        position_encoded = self.pe(word_embeddings)\n",
    "\n",
    "        mask = torch.tril(torch.ones((token_ids.size(dim=0), token_ids.size(dim=0)), device=self.device))\n",
    "        mask = mask == 0\n",
    "\n",
    "        self_attention_values = self.self_attention(position_encoded,\n",
    "                                                    position_encoded,\n",
    "                                                    position_encoded,\n",
    "                                                    mask=mask)\n",
    "\n",
    "        residual_connection_values = position_encoded + self_attention_values\n",
    "\n",
    "        regression_layer_output = self.regression_layer(residual_connection_values)\n",
    "\n",
    "        return regression_layer_output\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_tokens, labels = batch # collect input\n",
    "\n",
    "        output_better, output_worse = labels[0].split(2)\n",
    "\n",
    "        input_better = torch.cat((input_tokens[0], output_better))\n",
    "        input_worse = torch.cat((input_tokens[0], output_worse))\n",
    "\n",
    "        reward_better = self.forward(input_better)\n",
    "        reward_worse = self.forward(input_worse)\n",
    "        ## the equation is for the loss is...\n",
    "        ## -1 * log(sigmoid(reward_better - reward_worse)\n",
    "        ## For details, see: https://youtu.be/qPN_XZcJf_s\n",
    "        ## NOTE: reward_better and reward_worse are arrays with\n",
    "        ##       scores for each token. We only want the score for the\n",
    "        ##       last token, so we index that with [-1]\n",
    "        loss = -1 * torch.log(torch.sigmoid(reward_better[-1] - reward_worse[-1]))\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089393db-25c6-4cfc-9980-808336cdf55f",
   "metadata": {
    "id": "089393db-25c6-4cfc-9980-808336cdf55f"
   },
   "outputs": [],
   "source": [
    "reward_model = RewardModel(num_tokens=len(tokens),\n",
    "                           d_model=model_dimension,\n",
    "                           max_len=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46cc1c0-67cf-4463-beb5-065864182bf2",
   "metadata": {
    "id": "b46cc1c0-67cf-4463-beb5-065864182bf2"
   },
   "source": [
    "When we first create the **Reward Model** it is initialized with random **weights** and **biases**. For example, these are the initial **weights** used in the **Word Embedding Layer**..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23ce840-3868-4ea3-92fa-3feda1fbc672",
   "metadata": {
    "id": "e23ce840-3868-4ea3-92fa-3feda1fbc672"
   },
   "outputs": [],
   "source": [
    "reward_model.we.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a2adc-63f4-4191-ade9-d8efe5d4775c",
   "metadata": {
    "id": "dc9a2adc-63f4-4191-ade9-d8efe5d4775c"
   },
   "source": [
    "...however, what we want, is for the **Weights** to be the same as the ones in the Decoder-Only Transformer that we just trained. So, we can copy the **Weights** like this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff6cb9",
   "metadata": {
    "id": "7fff6cb9"
   },
   "outputs": [],
   "source": [
    "reward_model.we.weight = model.we.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7b2e8e-612d-4323-a354-00a89f8acd89",
   "metadata": {
    "id": "6b7b2e8e-612d-4323-a354-00a89f8acd89"
   },
   "source": [
    "...and we can verify that the **Weights** are now different by printing them out again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c37a43-d9ec-486b-ad24-bd6bac0716af",
   "metadata": {
    "id": "80c37a43-d9ec-486b-ad24-bd6bac0716af"
   },
   "outputs": [],
   "source": [
    "reward_model.we.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b5985a-0502-4403-8035-924b942bb553",
   "metadata": {
    "id": "b9b5985a-0502-4403-8035-924b942bb553"
   },
   "source": [
    "# BAM!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cb3762-3baa-45df-bba6-836a928e844d",
   "metadata": {
    "id": "89cb3762-3baa-45df-bba6-836a928e844d"
   },
   "source": [
    "Now let's copy the all of the other **Weights** in the model.\n",
    "\n",
    "**NOTE:** The only **Biases** in the model occur in the finally **Fully Connected Layer**, which we are not copying over to the **Reward Model** because we are replacing that layer with a new **Regression Layer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01cc091-8dc3-4f6e-9fe6-74879ca70d3f",
   "metadata": {
    "id": "c01cc091-8dc3-4f6e-9fe6-74879ca70d3f"
   },
   "outputs": [],
   "source": [
    "reward_model.self_attention.W_q.weight = model.self_attention.W_q.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b29bd7-988d-403f-9648-bb354ea3bf86",
   "metadata": {
    "id": "c4b29bd7-988d-403f-9648-bb354ea3bf86"
   },
   "outputs": [],
   "source": [
    "reward_model.self_attention.W_k.weight = model.self_attention.W_k.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d266b",
   "metadata": {
    "id": "088d266b"
   },
   "outputs": [],
   "source": [
    "reward_model.self_attention.W_v.weight = model.self_attention.W_v.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec4e634-656a-4fdb-99a2-37df6e4d451b",
   "metadata": {
    "id": "fec4e634-656a-4fdb-99a2-37df6e4d451b"
   },
   "source": [
    "Now we can verify that we successfully copied all of the **Weights** used for **Word Embedding** and calculating **Attention** by using for loops to print out all of the parameters (trainable **Weights** and **Biases**) in both models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9f4e0e-55d6-4f90-92cc-9135725f25b7",
   "metadata": {
    "id": "ad9f4e0e-55d6-4f90-92cc-9135725f25b7"
   },
   "outputs": [],
   "source": [
    "## Now print out the name and value for each named parameter\n",
    "## parameter in the model. Remember parameters are variables,\n",
    "## like Weights and Biases, that we can train.\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, torch.round(param.data, decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6479c-5fcf-44df-bfce-cbb4957c4752",
   "metadata": {
    "id": "63e6479c-5fcf-44df-bfce-cbb4957c4752"
   },
   "outputs": [],
   "source": [
    "## Now print out the name and value for each named parameter\n",
    "## parameter in the model. Remember parameters are variables,\n",
    "## like Weights and Biases, that we can train.\n",
    "for name, param in reward_model.named_parameters():\n",
    "    print(name, torch.round(param.data, decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa67cb0b-efa7-4f28-ac0a-d4a3fc6f4144",
   "metadata": {
    "id": "fa67cb0b-efa7-4f28-ac0a-d4a3fc6f4144"
   },
   "source": [
    "Now let's see how the **Reward Model** scores some prompt/response combinations. We'll start with prompt paired with a \"good\" response. In **RLHF** terminology, this is called the **Better** response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b554d-2234-4004-aa56-add592d3a899",
   "metadata": {
    "id": "3a7b554d-2234-4004-aa56-add592d3a899"
   },
   "outputs": [],
   "source": [
    "## Now let's score an input/output pair...\n",
    "## This is an example of a \"better\" response\n",
    "scores = reward_model(torch.tensor(tokens2ids(\"squatch eats what <EOS> pizza <EOS>\")))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fb7f0e-91a8-481d-af7f-0c4d7ac45773",
   "metadata": {
    "id": "06fb7f0e-91a8-481d-af7f-0c4d7ac45773"
   },
   "source": [
    "The final score for a prompt/response combination could be the average of all the outputs for the combination, or it could be just the last value. In this example, we're just going to use the last value, and we can index with with `[-1]`, which we do here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a55896-79bd-4f69-bc88-2fde27825524",
   "metadata": {
    "id": "94a55896-79bd-4f69-bc88-2fde27825524"
   },
   "outputs": [],
   "source": [
    "scores[-1] # use the last score as the output from the reward model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c059d5f5-2b65-4a78-90ce-bfc1e7ed17fa",
   "metadata": {
    "id": "c059d5f5-2b65-4a78-90ce-bfc1e7ed17fa"
   },
   "source": [
    "Now let's score a \"worse\" response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2c6e2-7c13-4491-a600-596d9f6c2b19",
   "metadata": {
    "id": "29b2c6e2-7c13-4491-a600-596d9f6c2b19"
   },
   "outputs": [],
   "source": [
    "## Now score another input/output pair...\n",
    "## This is an example of a \"worse\" response\n",
    "scores = reward_model(torch.tensor(tokens2ids(\"squatch eats what <EOS> awesome <EOS>\")))\n",
    "scores[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a3109-9ef7-4624-a63a-7c6ad5429a3e",
   "metadata": {
    "id": "a30a3109-9ef7-4624-a63a-7c6ad5429a3e"
   },
   "source": [
    "Right now, the \"worse\" response has a higher score than the \"better\" response. We hope to change that by training the **Reward Model**. So, the first thing we do is create a new dataset that pairs prompts with \"better\" and \"worse\" responses. The idea is that the \"better\" and \"worse\" responses are determined based on human preferences. In other worse, people were presented with both options and scored one response as better than the other.\n",
    "\n",
    "We'll start by creating a list of prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65705678-9205-4208-b083-ac3ab33d7d87",
   "metadata": {
    "id": "65705678-9205-4208-b083-ac3ab33d7d87"
   },
   "outputs": [],
   "source": [
    "rl_inputs = torch.tensor([tokens2ids(\"squatch eats what <EOS>\"),\n",
    "                          tokens2ids(\"squatch eats what <EOS>\"),\n",
    "                          tokens2ids(\"squatch eats what <EOS>\"),\n",
    "                          tokens2ids(\"squatch eats what <EOS>\"),\n",
    "                          tokens2ids(\"squatch eats what <EOS>\"),\n",
    "                          tokens2ids(\"squatch eats what <EOS>\"),\n",
    "                          tokens2ids(\"squatch eats what <EOS>\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GAKtrH-_qXYO",
   "metadata": {
    "id": "GAKtrH-_qXYO"
   },
   "source": [
    "Now let's create the reponses. We'll do this by concatonated a \"better\" response with a \"worse\" response. The \"better\" response comes first. Later, when we're in the `training_step()` we'll split these two responses apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dFFljaRpqWUy",
   "metadata": {
    "id": "dFFljaRpqWUy"
   },
   "outputs": [],
   "source": [
    "rl_labels = torch.tensor([tokens2ids(\"pizza <EOS> what <EOS>\"),\n",
    "                          tokens2ids(\"pizza <EOS> is <EOS>\"),\n",
    "                          tokens2ids(\"pizza <EOS> statquest <EOS>\"),\n",
    "                          tokens2ids(\"pizza <EOS> squatch <EOS>\"),\n",
    "                          tokens2ids(\"pizza <EOS> eats <EOS>\"),\n",
    "                          tokens2ids(\"pizza <EOS> norm <EOS>\"),\n",
    "                          tokens2ids(\"pizza <EOS> awesome <EOS>\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hpRJA7Haqqhr",
   "metadata": {
    "id": "hpRJA7Haqqhr"
   },
   "source": [
    "Lastly, let's put the new dataset in a `DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NkuDAlJbqprU",
   "metadata": {
    "id": "NkuDAlJbqprU"
   },
   "outputs": [],
   "source": [
    "## Now let's package everything up into a DataLoader...\n",
    "rl_dataset = TensorDataset(rl_inputs, rl_labels)\n",
    "rl_dataloader = DataLoader(rl_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MWB_vEK1qwLM",
   "metadata": {
    "id": "MWB_vEK1qwLM"
   },
   "source": [
    "Now that we have the data in a `DataLoader`, we can use it to train the **Reward Model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e786356-bc63-42ee-9d7a-f1b1f75c7305",
   "metadata": {
    "id": "5e786356-bc63-42ee-9d7a-f1b1f75c7305"
   },
   "outputs": [],
   "source": [
    "## now train the model\n",
    "trainer = L.Trainer(max_epochs=50, log_every_n_steps=2, deterministic=True)\n",
    "trainer.fit(reward_model, train_dataloaders=rl_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734dd0cb-bf71-4acc-bef2-a2cef5c3b38c",
   "metadata": {
    "id": "734dd0cb-bf71-4acc-bef2-a2cef5c3b38c"
   },
   "source": [
    "Now let's see if the **Reward** model now gives the \"better\" response a higher score than the \"worse\" response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a371a-0223-444e-b5b3-d3e34c9aafd6",
   "metadata": {
    "id": "af4a371a-0223-444e-b5b3-d3e34c9aafd6"
   },
   "outputs": [],
   "source": [
    "reward_better = reward_model(torch.tensor(tokens2ids(\"squatch eats what <EOS> pizza <EOS>\")))\n",
    "reward_better[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7100c4e5-ca98-4ed6-a001-40d7b212fa7a",
   "metadata": {
    "id": "7100c4e5-ca98-4ed6-a001-40d7b212fa7a"
   },
   "outputs": [],
   "source": [
    "reward_worse = reward_model(torch.tensor(tokens2ids(\"squatch eats what <EOS> awesome <EOS>\")))\n",
    "reward_worse[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c35f9-edd9-4f51-8cba-043b3ebe6af5",
   "metadata": {
    "id": "b08c35f9-edd9-4f51-8cba-043b3ebe6af5"
   },
   "source": [
    "And it does!\n",
    "\n",
    "# DOUBLE BAM!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44578ee9-0c62-48cc-883c-24c586a13f85",
   "metadata": {
    "id": "44578ee9-0c62-48cc-883c-24c586a13f85"
   },
   "source": [
    "**NOTE:** We can also calculate the **Loss** by hand to see if these scores result in a **Loss** value that is close to 0..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ac08b9-776b-4451-9b63-dc7af7c8e1ac",
   "metadata": {
    "id": "66ac08b9-776b-4451-9b63-dc7af7c8e1ac"
   },
   "outputs": [],
   "source": [
    "## See what the loss is...\n",
    "-1 * torch.log(torch.sigmoid(reward_better[-1] - reward_worse[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2addbc5b-c4a5-4f91-b945-e48a3c2d2335",
   "metadata": {
    "id": "2addbc5b-c4a5-4f91-b945-e48a3c2d2335"
   },
   "source": [
    "...and we see that the **Loss** is super close to 0. In other words, the scores generated for the \"better\" and \"worse\" responses minimize the **Loss**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4df6afa-6581-4947-a20a-1bbf4aec46dc",
   "metadata": {
    "id": "b4df6afa-6581-4947-a20a-1bbf4aec46dc"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0089d6cb-815b-48e5-9238-1f3e00ae33ed",
   "metadata": {
    "id": "0089d6cb-815b-48e5-9238-1f3e00ae33ed"
   },
   "source": [
    "Now let's see how the **Reward Model** scores prompt/response pairs (with \"better\" and \"worse\" responses) for something it has never seen before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf629e-3068-45e8-9b21-27f6f22eb489",
   "metadata": {
    "id": "41bf629e-3068-45e8-9b21-27f6f22eb489"
   },
   "outputs": [],
   "source": [
    "## Now let's score an input/output pair that the Reward Model has never seen before...\n",
    "## This is an example of a \"better\" response:\n",
    "reward_better = reward_model(torch.tensor(tokens2ids(\"norm eats what <EOS> pizza <EOS>\")))\n",
    "reward_better[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73612b5c-7a14-4d10-a563-3429f9058e0b",
   "metadata": {
    "id": "73612b5c-7a14-4d10-a563-3429f9058e0b"
   },
   "outputs": [],
   "source": [
    "## Now score another input/output pair that the Reward Model has never seen before...\n",
    "## This is an example of a \"worse\" response:\n",
    "reward_worse = reward_model(torch.tensor(tokens2ids(\"norm eats what <EOS> awesome <EOS>\")))\n",
    "reward_worse[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d120f90-9124-4204-a9a4-9917ad467285",
   "metadata": {
    "id": "9d120f90-9124-4204-a9a4-9917ad467285"
   },
   "source": [
    "...and we see that the \"Better\" response scores higher than the \"worse\" resposne. This is good. It means we can use the **Reward Model** to train the original model to correctly respond to new prompts that it was not originally trained to handel. This is how we train a model with **Reinforcement Learning with Human Feedback**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f85f8c-1556-4260-9e32-e7ef64954258",
   "metadata": {
    "id": "30f85f8c-1556-4260-9e32-e7ef64954258"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfa142f-974d-4ebb-b9d3-c24aad112d05",
   "metadata": {
    "id": "abfa142f-974d-4ebb-b9d3-c24aad112d05"
   },
   "source": [
    "# Train the original model with RLHF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94ca85a-ad14-4bbe-8edc-981fc6c7128d",
   "metadata": {
    "id": "e94ca85a-ad14-4bbe-8edc-981fc6c7128d"
   },
   "source": [
    "First, let's see what the original model generates when given a prompt it was not trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9429e9-71cb-4513-9da5-c44492e3368d",
   "metadata": {
    "id": "9c9429e9-71cb-4513-9da5-c44492e3368d"
   },
   "outputs": [],
   "source": [
    "generate_output(model, torch.tensor(tokens2ids(\"norm eats what <EOS>\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca81bc4-7ee2-45c7-95e5-f73175540a8a",
   "metadata": {
    "id": "fca81bc4-7ee2-45c7-95e5-f73175540a8a"
   },
   "source": [
    "And we see that, right now, the original model does not respond to the propmt correctly. Ideally, the response would be `pizza <EOS`. So let's see if we can use the **Reward Model** to train the original model to generate the correct response.\n",
    "\n",
    "To do this, we'll need to modify the code for the `training_step` method to use the **Reward Model** when it calculates the **Loss**. Thus, we'll create a new class that is identical to the class used to create the original Decoder-Only Transformer, except it has a different `training_step` method. In other words, this new model will have the same **Word Embedding Layer**, **Attention Layer** and **Fully Connected Layer** that we used in the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3564d6-28b8-48c0-a798-0ada506ed428",
   "metadata": {
    "id": "7b3564d6-28b8-48c0-a798-0ada506ed428"
   },
   "outputs": [],
   "source": [
    "class DecoderOnlyTransformer_RLHF(L.LightningModule):\n",
    "\n",
    "    def __init__(self, num_tokens=4, d_model=2, max_len=6):\n",
    "\n",
    "        super().__init__()\n",
    "        L.seed_everything(seed=42, workers=True)\n",
    "\n",
    "        self.we = nn.Embedding(num_embeddings=num_tokens,\n",
    "                               embedding_dim=d_model)\n",
    "\n",
    "        self.pe = PositionEncoding(d_model=d_model,\n",
    "                                   max_len=max_len)\n",
    "\n",
    "        self.self_attention = Attention(d_model=d_model)\n",
    "\n",
    "        self.fc_layer = nn.Linear(in_features=d_model,\n",
    "                                  out_features=num_tokens)\n",
    "\n",
    "        # self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.gamma = torch.tensor(0.99)\n",
    "        self.reward = torch.tensor(0)\n",
    "        self.all_ids = torch.tensor(0)\n",
    "\n",
    "\n",
    "    def forward(self, token_ids):\n",
    "\n",
    "        # print(\"token_ids:\", token_ids)\n",
    "\n",
    "        word_embeddings = self.we(token_ids)\n",
    "        # print(\"word_embeddings:\", word_embeddings)\n",
    "\n",
    "        position_encoded = self.pe(word_embeddings)\n",
    "        # print(\"position_encoded:\", position_encoded)\n",
    "\n",
    "        mask = torch.tril(torch.ones((token_ids.size(dim=0), token_ids.size(dim=0)), device=self.device))\n",
    "        mask = mask == 0\n",
    "\n",
    "        self_attention_values = self.self_attention(position_encoded,\n",
    "                                                    position_encoded,\n",
    "                                                    position_encoded,\n",
    "                                                    mask=mask)\n",
    "\n",
    "        residual_connection_values = position_encoded + self_attention_values\n",
    "\n",
    "        fc_layer_output = self.fc_layer(residual_connection_values)\n",
    "\n",
    "        return fc_layer_output\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_tokens, labels = batch # collect input\n",
    "\n",
    "        model_input = input_tokens[0]\n",
    "\n",
    "        predictions = self.forward(model_input)\n",
    "\n",
    "        predicted_id = torch.tensor([torch.argmax(predictions[-1,:])])\n",
    "        guess_one_hot = torch.zeros(len(predictions[-1,:]))\n",
    "        guess_one_hot[predicted_id] = 1\n",
    "\n",
    "        self.all_ids = torch.cat((model_input, predicted_id))\n",
    "        self.all_ids = torch.cat((self.all_ids, torch.tensor(tokens2ids(\"<EOS>\"))))\n",
    "\n",
    "        self.reward = reward_model(self.all_ids)[-1]\n",
    "\n",
    "        # print(\"predictions[-1,:]:\", predictions[-1,:])\n",
    "        soft_predictions = F.softmax(predictions[-1,:])\n",
    "        # print(\"soft_predictions:\", soft_predictions)\n",
    "\n",
    "        # loss = -1 * predictions[-1,predicted_id] * self.gamma * self.reward\n",
    "        loss = -1 * soft_predictions[predicted_id] * self.gamma * self.reward\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b6476b-f8c4-4d35-8717-385ee672c4a1",
   "metadata": {
    "id": "98b6476b-f8c4-4d35-8717-385ee672c4a1"
   },
   "source": [
    "Since we want to copy every single parameter from the original mdoel to the new model, so that it acts the same, we can use `load_state_dict()` and `stat_dict()` to copy things quickly and easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc1e9e8-3c2c-4c1d-abc2-dc175a6cef5d",
   "metadata": {
    "id": "bbc1e9e8-3c2c-4c1d-abc2-dc175a6cef5d"
   },
   "outputs": [],
   "source": [
    "new_model = DecoderOnlyTransformer_RLHF(num_tokens=len(tokens),\n",
    "                                        d_model=model_dimension,\n",
    "                                        max_len=max_length)\n",
    "# Copy weights from the original pretrained model to new_model\n",
    "new_model.load_state_dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a3f2e9-88be-458b-b0e4-4527572e5f69",
   "metadata": {
    "id": "f9a3f2e9-88be-458b-b0e4-4527572e5f69"
   },
   "source": [
    "We can verify that both models have the same parameters by printing them out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30e1e3f-5cab-4c23-afde-e053a9f344d0",
   "metadata": {
    "id": "a30e1e3f-5cab-4c23-afde-e053a9f344d0"
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, torch.round(param.data, decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00fb48-eadf-42e7-b816-4799c8cbc0bf",
   "metadata": {
    "id": "9e00fb48-eadf-42e7-b816-4799c8cbc0bf"
   },
   "outputs": [],
   "source": [
    "for name, param in new_model.named_parameters():\n",
    "    print(name, torch.round(param.data, decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008437f-ba2f-4bdf-966f-11647ebd4592",
   "metadata": {
    "id": "7008437f-ba2f-4bdf-966f-11647ebd4592"
   },
   "source": [
    "We can also verify that the new model responds to the new prompt in the same way as the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14de03d-eef3-42d7-8c65-af80bff2fb04",
   "metadata": {
    "id": "c14de03d-eef3-42d7-8c65-af80bff2fb04"
   },
   "outputs": [],
   "source": [
    "generate_output(new_model, torch.tensor(tokens2ids(\"norm eats what <EOS>\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ad20d9-bb4a-4d18-bd31-481382ba4804",
   "metadata": {
    "id": "e4ad20d9-bb4a-4d18-bd31-481382ba4804"
   },
   "source": [
    "Since the new model's response to the prompt is exactly the same as we got with the old model, we will now train the new model with **Reinforcement Learning with Human Feedback**. First, let's create a dataset that only provides a prompt, and has no label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ce4f8-d1ce-4a34-bcd0-7a3f4430e00c",
   "metadata": {
    "id": "429ce4f8-d1ce-4a34-bcd0-7a3f4430e00c"
   },
   "outputs": [],
   "source": [
    "rlhf_inputs = torch.tensor([tokens2ids(\"norm eats what <EOS>\")])\n",
    "\n",
    "rlhf_labels = torch.tensor([tokens2ids(\"<PAD>\")])\n",
    "\n",
    "## Now let's package everything up into a DataLoader...\n",
    "rlhf_dataset = TensorDataset(rlhf_inputs, rlhf_labels)\n",
    "rlhf_dataloader = DataLoader(rlhf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d374d82-3403-49fa-9997-2f6f6a0378f5",
   "metadata": {
    "id": "4d374d82-3403-49fa-9997-2f6f6a0378f5"
   },
   "outputs": [],
   "source": [
    "%xmode Minimal\n",
    "## now see if we can train the model\n",
    "# trainer = L.Trainer(max_epochs=1000, log_every_n_steps=2, accelerator=\"cpu\", deterministic=True)\n",
    "trainer = L.Trainer(max_epochs=10, log_every_n_steps=2, accelerator=\"cpu\", deterministic=True)\n",
    "trainer.fit(new_model, train_dataloaders=rlhf_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932d5acf-4968-436b-a983-a6e4b21bd0af",
   "metadata": {
    "id": "932d5acf-4968-436b-a983-a6e4b21bd0af"
   },
   "source": [
    "Now let's see if the model, trained with **RLHF**, responds correctly to the new prompt..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e850a253-035e-4209-a7bb-99f0500b8cee",
   "metadata": {
    "id": "e850a253-035e-4209-a7bb-99f0500b8cee"
   },
   "outputs": [],
   "source": [
    "generate_output(new_model, torch.tensor(tokens2ids(\"norm eats what <EOS>\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcb82a0-474c-495e-b4c7-d5deecdb600a",
   "metadata": {
    "id": "cdcb82a0-474c-495e-b4c7-d5deecdb600a"
   },
   "source": [
    "...and it does!!! At least, on my computer I get `pizza <EOS>` as the output. Sometimes on Google Colab I get `pizza pizza pizza...`, which, while not as ideal as what happened on my laptop, is still an improvement over what we got before, which was, `is eats is eats is eats is`. In other words, we successfully trained our model with **RLHF**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabafb41-3942-427c-8542-a2f5ba48074f",
   "metadata": {
    "id": "eabafb41-3942-427c-8542-a2f5ba48074f"
   },
   "source": [
    "# TRIPLE BAM!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d2a929-adba-44db-a7f1-3347c5e1ea4b",
   "metadata": {
    "id": "d2d2a929-adba-44db-a7f1-3347c5e1ea4b"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4039261-695d-45ce-8a82-9a3f8bda8e88",
   "metadata": {
    "id": "c4039261-695d-45ce-8a82-9a3f8bda8e88"
   },
   "source": [
    "# NOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130c2abd-0f22-4645-a1bb-af51df4a5f66",
   "metadata": {
    "id": "130c2abd-0f22-4645-a1bb-af51df4a5f66"
   },
   "source": [
    "We can use **TensorBoard** to see if we have minimized the overall loss of the model.\n",
    "\n",
    "**NOTE:** If you want to make use **TensorBoard**, make sure you are calling `self.log(\"train_loss\", loss)` (or something like that) in the `training_step()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4yCJdp3XYzW6",
   "metadata": {
    "id": "4yCJdp3XYzW6"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# ## NOTE: If you **don't** need to install anything, you can comment out the\n",
    "# ##       next line.\n",
    "# ##\n",
    "# ##       If you **do** need to install something, just know that you may need to\n",
    "# ##       restart your session for python to find the new module(s).\n",
    "# ##\n",
    "# ##       To restart your session:\n",
    "# ##       - In Google Colab, click on the \"Runtime\" menu and select\n",
    "# ##         \"Restart Session\" from the pulldown menu\n",
    "# ##       - In a local jupyter notebook, click on the \"Kernel\" menu and select\n",
    "# ##         \"Restart Kernel\" from the pulldown menu\n",
    "# ##\n",
    "# ##       Also, installing can take a few minutes, so go get yourself a snack!\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f959ac3-2077-442b-8a15-513ec124ac16",
   "metadata": {
    "id": "6f959ac3-2077-442b-8a15-513ec124ac16"
   },
   "outputs": [],
   "source": [
    "## Load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56dcda6-85dc-4cc0-9f71-fb8dd972c9fe",
   "metadata": {
    "id": "b56dcda6-85dc-4cc0-9f71-fb8dd972c9fe"
   },
   "outputs": [],
   "source": [
    "## Now launch tensorboard within the jupyter notebook\n",
    "# %tensorboard --logdir=lightning_logs/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
